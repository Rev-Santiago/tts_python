<!DOCTYPE html>
<html>
<head>
    <title>TTS Local Test</title>
    <style>
        body { font-family: Arial, sans-serif; padding: 20px; }
        textarea, select, button { margin-bottom: 10px; width: 100%; max-width: 400px; padding: 8px; }
    </style>
</head>
<body>
    <h2>TTS WebSocket Test</h2>
    
    <label for="text">Text to synthesize:</label><br>
    <textarea id="text" rows="3">Testing the connection from my local frontend.</textarea><br>
    
    <label for="voiceSelect">Choose Voice:</label><br>
    <select id="voiceSelect">
        <optgroup label="Native Qwen3 Voices">
            <option value="vivian" selected>Vivian (Female)</option>
            <option value="serena">Serena (Female)</option>
            <option value="ono_anna">Ono Anna (Female)</option>
            <option value="sohee">Sohee (Female)</option>
            <option value="uncle_fu">Uncle Fu (Male)</option>
            <option value="ryan">Ryan (Male)</option>
            <option value="aiden">Aiden (Male)</option>
            <option value="eric">Eric (Male)</option>
            <option value="dylan">Dylan (Male)</option>
        </optgroup>
        <optgroup label="OpenAI-Compatible Aliases">
            <option value="alloy">Alloy (maps to Vivian)</option>
            <option value="echo">Echo (maps to Ryan)</option>
            <option value="fable">Fable (maps to Sophia)</option>
            <option value="nova">Nova (maps to Isabella)</option>
            <option value="onyx">Onyx (maps to Evan)</option>
            <option value="shimmer">Shimmer (maps to Lily)</option>
        </optgroup>
    </select><br>

    <button id="play">Generate & Play</button>
    <p id="status">Status: Ready</p>

    <script>
    let audioCtx;
    let nextStartTime = 0; // Track when the next chunk should start

    document.getElementById('play').onclick = async () => {
        if (!audioCtx) audioCtx = new AudioContext({ sampleRate: 22050 });
        
        // Resume context if suspended (browser security policy)
        if (audioCtx.state === 'suspended') await audioCtx.resume();
        
        document.getElementById('status').innerText = "Status: Connecting...";
        
        // Reset timing for new request
        nextStartTime = audioCtx.currentTime;

        const ws = new WebSocket("ws://192.168.2.56:8010/api/ws/generate");
        ws.binaryType = 'arraybuffer';

        ws.onopen = () => {
            // Include the selected voice in the JSON payload
            const payload = {
                text: document.getElementById('text').value,
                voice: document.getElementById('voiceSelect').value,
                speed: 1.0
            };
            ws.send(JSON.stringify(payload));
            
            document.getElementById('status').innerText = "Status: Receiving Audio...";
        };

        ws.onmessage = async (event) => {
            if (event.data instanceof ArrayBuffer) {
                const int16 = new Int16Array(event.data);
                const float32 = new Float32Array(int16.length);
                for (let i = 0; i < int16.length; i++) float32[i] = int16[i] / 32768;

                const buffer = audioCtx.createBuffer(1, float32.length, 22050);
                buffer.getChannelData(0).set(float32);
                
                const source = audioCtx.createBufferSource();
                source.buffer = buffer;
                source.connect(audioCtx.destination);
                
                // Ensure we don't schedule in the past
                const playTime = Math.max(nextStartTime, audioCtx.currentTime);
                source.start(playTime);
                
                // Update the start time for the next chunk
                nextStartTime = playTime + buffer.duration;
            } else {
                const msg = JSON.parse(event.data);
                if (msg.type === 'complete') document.getElementById('status').innerText = "Status: Done";
            }
        };
    };
    </script>
</body>
</html>